{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Notebook demo: RTMD database\n",
        "\n",
        "This notebook now includes a short Python snippet to connect to the local RTMD PostgreSQL instance and run a quick `COUNT(*)` test against `social_posts`.\n",
        "\n",
        "For a more complete demo and partition management, see `python/connect_and_demo.py` and `scripts/create_month_partitions.ps1`.\n",
        "\n",
        "Steps:\n",
        "1. Ensure DB is running (`docker compose up -d`).\n",
        "2. Apply migrations (`scripts\\apply_migrations.ps1`).\n",
        "3. Run the code cell below to confirm connection and counts.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Demo: Connect to RTMD DB (Python)\n",
        "\n",
        "# Ensure you have installed dependencies: `pip install -r requirements.txt`\n",
        "# Set environment variables (or copy `.env.example` to `.env` and load it).\n",
        "\n",
        "import os\n",
        "import psycopg2\n",
        "from psycopg2.extras import RealDictCursor\n",
        "\n",
        "DB_HOST = os.getenv('DB_HOST','localhost')\n",
        "DB_PORT = int(os.getenv('DB_PORT',5432))\n",
        "DB_NAME = os.getenv('DB_NAME','rtmd')\n",
        "DB_USER = os.getenv('DB_USER','rtmd_user')\n",
        "DB_PASS = os.getenv('DB_PASS','change_me')\n",
        "\n",
        "print('DB connection settings:', DB_HOST, DB_PORT, DB_NAME, DB_USER)\n",
        "\n",
        "try:\n",
        "    conn = psycopg2.connect(host=DB_HOST, port=DB_PORT, dbname=DB_NAME, user=DB_USER, password=DB_PASS)\n",
        "    with conn.cursor(cursor_factory=RealDictCursor) as cur:\n",
        "        cur.execute(\"SELECT count(*) AS total FROM social_posts;\")\n",
        "        print('social_posts count:', cur.fetchone()['total'])\n",
        "    conn.close()\n",
        "except Exception as e:\n",
        "    print('Connection failed:', e)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gQEQ-4CQhzl2",
        "outputId": "6d370bc4-b7cd-49a2-fb91-0d38544e012a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Connection successful!\n",
            "2.6.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-1522937468.py:8: DeprecationWarning: version is deprecated and will be removed in Python 3.14\n",
            "  print(sqlite3.version)\n"
          ]
        }
      ],
      "source": [
        "import sqlite3\n",
        "\n",
        "# This will work without any installation\n",
        "conn = sqlite3.connect('my_database.db')\n",
        "print(\"Connection successful!\")\n",
        "\n",
        "\n",
        "print(sqlite3.version)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4a3XMU1bkA6e",
        "outputId": "d99fe680-70c4-48f0-f37a-893b26dd8b1e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Problem with User: Execution failed on sql 'SELECT * FROM User LIMIT 3': no such table: User\n",
            "Problem with Location: Execution failed on sql 'SELECT * FROM Location LIMIT 3': no such table: Location\n",
            "Problem with Disaster: Execution failed on sql 'SELECT * FROM Disaster LIMIT 3': no such table: Disaster\n",
            "Problem with Disaster_Location: Execution failed on sql 'SELECT * FROM Disaster_Location LIMIT 3': no such table: Disaster_Location\n",
            "Problem with Credibility: Execution failed on sql 'SELECT * FROM Credibility LIMIT 3': no such table: Credibility\n",
            "Problem with Stream: Execution failed on sql 'SELECT * FROM Stream LIMIT 3': no such table: Stream\n",
            "Problem with Post: Execution failed on sql 'SELECT * FROM Post LIMIT 3': no such table: Post\n",
            "Problem with Model_Result: Execution failed on sql 'SELECT * FROM Model_Result LIMIT 3': no such table: Model_Result\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "tables = [\n",
        "    'User', 'Location', 'Disaster', 'Disaster_Location',\n",
        "    'Credibility', 'Stream', 'Post', 'Model_Result'\n",
        "]\n",
        "\n",
        "for table in tables:\n",
        "    try:\n",
        "        df = pd.read_sql_query(f\"SELECT * FROM {table} LIMIT 3\", conn)\n",
        "        print(f\"\\n{table} — first few rows:\")\n",
        "        print(df)\n",
        "        print(f\"Total rows: {len(pd.read_sql_query(f'SELECT * FROM {table}', conn))}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Problem with {table}: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ggZmG9SokEQR",
        "outputId": "7a94858e-88ec-4440-f518-ed5156ca85a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "Connected to: /content/drive/MyDrive/disaster_monitoring.db\n",
            "All tables are now created (or already existed).\n"
          ]
        }
      ],
      "source": [
        "# Step 1: Mount Drive (run this first every time after restart)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# Step 2: Connect to the SAME persistent file\n",
        "import sqlite3\n",
        "DB_PATH = '/content/drive/MyDrive/disaster_monitoring.db'\n",
        "conn = sqlite3.connect(DB_PATH)\n",
        "cursor = conn.cursor()\n",
        "\n",
        "print(\"Connected to:\", DB_PATH)\n",
        "\n",
        "# Very important in SQLite - enable foreign keys\n",
        "cursor.execute(\"PRAGMA foreign_keys = ON;\")\n",
        "\n",
        "# Step 3: Create ALL tables (IF NOT EXISTS so it's safe to re-run)\n",
        "cursor.executescript('''\n",
        "CREATE TABLE IF NOT EXISTS User (\n",
        "    user_id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "    name TEXT NOT NULL,\n",
        "    email TEXT NOT NULL UNIQUE,\n",
        "    password_hash TEXT NOT NULL,\n",
        "    role TEXT NOT NULL\n",
        ");\n",
        "\n",
        "CREATE TABLE IF NOT EXISTS Location (\n",
        "    location_id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "    name TEXT NOT NULL,\n",
        "    district TEXT,\n",
        "    province TEXT\n",
        ");\n",
        "\n",
        "CREATE TABLE IF NOT EXISTS Disaster (\n",
        "    disaster_id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "    disaster_type TEXT NOT NULL,\n",
        "    severity TEXT,\n",
        "    confidence_score REAL DEFAULT 0.0,\n",
        "    date_time TEXT NOT NULL,\n",
        "    status TEXT NOT NULL\n",
        ");\n",
        "\n",
        "CREATE TABLE IF NOT EXISTS Disaster_Location (\n",
        "    disaster_id INTEGER NOT NULL,\n",
        "    location_id INTEGER NOT NULL,\n",
        "    PRIMARY KEY (disaster_id, location_id),\n",
        "    FOREIGN KEY (disaster_id) REFERENCES Disaster(disaster_id) ON DELETE CASCADE,\n",
        "    FOREIGN KEY (location_id) REFERENCES Location(location_id) ON DELETE CASCADE\n",
        ");\n",
        "\n",
        "CREATE TABLE IF NOT EXISTS Credibility (\n",
        "    credibility_id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "    score REAL NOT NULL DEFAULT 0.5,\n",
        "    verification_status TEXT NOT NULL\n",
        ");\n",
        "\n",
        "CREATE TABLE IF NOT EXISTS Stream (\n",
        "    stream_id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "    source_platform TEXT NOT NULL,\n",
        "    last_update_timestamp TEXT NOT NULL DEFAULT (datetime('now'))\n",
        ");\n",
        "\n",
        "CREATE TABLE IF NOT EXISTS Post (\n",
        "    post_id INTEGER PRIMARY KEY,\n",
        "    post_text TEXT,\n",
        "    post_image TEXT,\n",
        "    language TEXT,\n",
        "    platform TEXT NOT NULL,\n",
        "    timestamp TEXT NOT NULL,\n",
        "    credibility_id INTEGER,\n",
        "    stream_id INTEGER,\n",
        "    disaster_id INTEGER,\n",
        "    FOREIGN KEY (credibility_id) REFERENCES Credibility(credibility_id) ON DELETE SET NULL,\n",
        "    FOREIGN KEY (stream_id)      REFERENCES Stream(stream_id)          ON DELETE SET NULL,\n",
        "    FOREIGN KEY (disaster_id)    REFERENCES Disaster(disaster_id)      ON DELETE SET NULL\n",
        ");\n",
        "\n",
        "CREATE TABLE IF NOT EXISTS Model_Result (\n",
        "    result_id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "    post_id INTEGER NOT NULL,\n",
        "    accuracy REAL,\n",
        "    disaster_label TEXT,\n",
        "    model_type TEXT NOT NULL,\n",
        "    confidence_score REAL NOT NULL DEFAULT 0.0,\n",
        "    FOREIGN KEY (post_id) REFERENCES Post(post_id) ON DELETE CASCADE\n",
        ");\n",
        "''')\n",
        "\n",
        "conn.commit()\n",
        "print(\"All tables are now created (or already existed).\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iPzTSgx8lC1z",
        "outputId": "e52b425a-d6c0-4dc4-cda4-1230c55df122"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Existing tables: ['User', 'sqlite_sequence', 'Location', 'Disaster', 'Disaster_Location', 'Credibility', 'Stream', 'Post', 'Model_Result']\n",
            "\n",
            "Users table content:\n",
            "Empty DataFrame\n",
            "Columns: [user_id, name, email, password_hash, role]\n",
            "Index: []\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Quick test: see if tables exist now\n",
        "cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
        "tables = cursor.fetchall()\n",
        "print(\"Existing tables:\", [t[0] for t in tables])\n",
        "\n",
        "# Try one table\n",
        "print(\"\\nUsers table content:\")\n",
        "print(pd.read_sql_query(\"SELECT * FROM User LIMIT 3\", conn))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lu2J_K3XJfPS",
        "outputId": "9b8f8c2a-27ad-4392-b6e2-2868595f1a2e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "Existing tables: ['User', 'sqlite_sequence', 'Location', 'Disaster', 'Disaster_Location', 'Credibility', 'Stream', 'Post', 'Model_Result']\n",
            "\n",
            "Users table content:\n",
            "Empty DataFrame\n",
            "Columns: [user_id, name, email, password_hash, role]\n",
            "Index: []\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "import pandas as pd\n",
        "import sqlite3\n",
        "\n",
        "# Re-establish connection and cursor for robustness against kernel restarts\n",
        "DB_PATH = '/content/drive/MyDrive/disaster_monitoring.db'\n",
        "conn = sqlite3.connect(DB_PATH)\n",
        "cursor = conn.cursor()\n",
        "\n",
        "# Quick test: see if tables exist now\n",
        "cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
        "tables = cursor.fetchall()\n",
        "print(\"Existing tables:\", [t[0] for t in tables])\n",
        "\n",
        "# Try one table\n",
        "print(\"\\nUsers table content:\")\n",
        "print(pd.read_sql_query(\"SELECT * FROM User LIMIT 3\", conn))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iBbEi0T7KxI8",
        "outputId": "977bd959-c5d2-4af6-d67e-fc66c22ffd5c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3 main views created.\n",
            "\n",
            "Active disasters view:\n",
            "Empty DataFrame\n",
            "Columns: [disaster_id, disaster_type, severity, confidence_score, date_time, status, affected_locations]\n",
            "Index: []\n"
          ]
        }
      ],
      "source": [
        "cursor.execute(\"\"\"\n",
        "CREATE VIEW IF NOT EXISTS v_active_disasters AS\n",
        "SELECT\n",
        "    d.disaster_id,\n",
        "    d.disaster_type,\n",
        "    d.severity,\n",
        "    d.confidence_score,\n",
        "    d.date_time,\n",
        "    d.status,\n",
        "    GROUP_CONCAT(l.name || ' (' || l.province || ')') AS affected_locations\n",
        "FROM Disaster d\n",
        "LEFT JOIN Disaster_Location dl ON d.disaster_id = dl.disaster_id\n",
        "LEFT JOIN Location l ON dl.location_id = l.location_id\n",
        "WHERE d.status IN ('Active', 'Monitoring')\n",
        "GROUP BY d.disaster_id\n",
        "ORDER BY d.date_time DESC;\n",
        "\"\"\")\n",
        "\n",
        "cursor.execute(\"\"\"\n",
        "CREATE VIEW IF NOT EXISTS v_high_confidence_posts AS\n",
        "SELECT\n",
        "    p.post_id,\n",
        "    p.post_text,\n",
        "    p.platform,\n",
        "    p.timestamp,\n",
        "    p.language,\n",
        "    c.score AS credibility_score,\n",
        "    c.verification_status,\n",
        "    mr.disaster_label,\n",
        "    mr.confidence_score AS model_confidence\n",
        "FROM Post p\n",
        "LEFT JOIN Credibility c ON p.credibility_id = c.credibility_id\n",
        "LEFT JOIN Model_Result mr ON p.post_id = mr.post_id\n",
        "WHERE mr.confidence_score > 0.75\n",
        "ORDER BY mr.confidence_score DESC;\n",
        "\"\"\")\n",
        "\n",
        "cursor.execute(\"\"\"\n",
        "CREATE VIEW IF NOT EXISTS v_posts_per_disaster AS\n",
        "SELECT\n",
        "    d.disaster_id,\n",
        "    d.disaster_type,\n",
        "    d.severity,\n",
        "    COUNT(p.post_id) AS post_count,\n",
        "    COUNT(CASE WHEN p.language = 'si' THEN 1 END) AS sinhala_posts,\n",
        "    COUNT(CASE WHEN p.language = 'ta' THEN 1 END) AS tamil_posts,\n",
        "    AVG(mr.confidence_score) AS avg_model_confidence\n",
        "FROM Disaster d\n",
        "LEFT JOIN Post p ON d.disaster_id = p.disaster_id\n",
        "LEFT JOIN Model_Result mr ON p.post_id = mr.post_id\n",
        "GROUP BY d.disaster_id\n",
        "ORDER BY post_count DESC;\n",
        "\"\"\")\n",
        "\n",
        "conn.commit()\n",
        "print(\"3 main views created.\")\n",
        "\n",
        "# Quick check\n",
        "print(\"\\nActive disasters view:\")\n",
        "print(pd.read_sql_query(\"SELECT * FROM v_active_disasters\", conn))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G0Qq-yENLCsK",
        "outputId": "2c48b7b4-6075-47cf-d2b5-d1eb721b5499"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Active disasters with locations:\n",
            "Empty DataFrame\n",
            "Columns: [disaster_id, disaster_type, severity, confidence_score, date_time, status, affected_locations]\n",
            "Index: []\n",
            "\n",
            "High confidence detections:\n",
            "Empty DataFrame\n",
            "Columns: [post_id, post_text, platform, timestamp, language, credibility_score, verification_status, disaster_label, model_confidence]\n",
            "Index: []\n",
            "\n",
            "Posts count & language breakdown per disaster:\n",
            "Empty DataFrame\n",
            "Columns: [disaster_id, disaster_type, severity, post_count, sinhala_posts, tamil_posts, avg_model_confidence]\n",
            "Index: []\n",
            "\n",
            "Most recent 5 posts overall:\n",
            "Empty DataFrame\n",
            "Columns: [post_id, platform, timestamp, post_text]\n",
            "Index: []\n",
            "\n",
            "Average model confidence per disaster type:\n",
            "Empty DataFrame\n",
            "Columns: [disaster_type, avg_conf]\n",
            "Index: []\n",
            "\n",
            "Posts from low-credibility sources:\n",
            "Empty DataFrame\n",
            "Columns: [platform, post_text, score, verification_status]\n",
            "Index: []\n"
          ]
        }
      ],
      "source": [
        "queries = [\n",
        "    (\"Active disasters with locations\", \"SELECT * FROM v_active_disasters\"),\n",
        "    (\"High confidence detections\", \"SELECT * FROM v_high_confidence_posts LIMIT 5\"),\n",
        "    (\"Posts count & language breakdown per disaster\", \"SELECT * FROM v_posts_per_disaster\"),\n",
        "    (\"Most recent 5 posts overall\", \"SELECT post_id, platform, timestamp, post_text FROM Post ORDER BY timestamp DESC LIMIT 5\"),\n",
        "    (\"Average model confidence per disaster type\", \"\"\"\n",
        "        SELECT d.disaster_type, AVG(mr.confidence_score) AS avg_conf\n",
        "        FROM Disaster d\n",
        "        JOIN Post p ON d.disaster_id = p.disaster_id\n",
        "        JOIN Model_Result mr ON p.post_id = mr.post_id\n",
        "        GROUP BY d.disaster_type\n",
        "        ORDER BY avg_conf DESC\n",
        "    \"\"\"),\n",
        "    (\"Posts from low-credibility sources\", \"\"\"\n",
        "        SELECT p.platform, p.post_text, c.score, c.verification_status\n",
        "        FROM Post p\n",
        "        JOIN Credibility c ON p.credibility_id = c.credibility_id\n",
        "        WHERE c.score < 0.5\n",
        "    \"\"\")\n",
        "]\n",
        "\n",
        "for title, sql in queries:\n",
        "    print(f\"\\n{title}:\")\n",
        "    try:\n",
        "        df = pd.read_sql_query(sql, conn)\n",
        "        print(df)\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_S-MUQ-RLMoU",
        "outputId": "00f2b39a-0ed0-4c19-f38a-fd99872d5b0b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Duplicate email → unexpectedly succeeded\n",
            "After deleting disaster 4 → check if related Disaster_Location rows are gone:\n",
            "Empty DataFrame\n",
            "Columns: [disaster_id, location_id]\n",
            "Index: []\n"
          ]
        }
      ],
      "source": [
        "# Should fail (duplicate email)\n",
        "try:\n",
        "    cursor.execute(\"INSERT INTO User (name, email, password_hash, role) VALUES ('Test Dup', 'admin@disaster.lk', 'xxx', 'test')\")\n",
        "    conn.commit()\n",
        "    print(\"Duplicate email → unexpectedly succeeded\")\n",
        "except sqlite3.IntegrityError:\n",
        "    print(\"Duplicate email → correctly blocked (UNIQUE constraint works)\")\n",
        "\n",
        "# Cascade test\n",
        "cursor.execute(\"DELETE FROM Disaster WHERE disaster_id = 4\")   # assuming you have disaster_id=4\n",
        "conn.commit()\n",
        "print(\"After deleting disaster 4 → check if related Disaster_Location rows are gone:\")\n",
        "print(pd.read_sql_query(\"SELECT * FROM Disaster_Location WHERE disaster_id = 4\", conn))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
