# -*- coding: utf-8 -*-
"""LF_Task_1_a_.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1FyfU798m_AYsgbhAWlo0gw-nKOhljEkX
"""

from google.colab import drive
drive.mount('/content/drive')

import torch
import json
import timm
import torch.nn as nn
import torch.nn.functional as F
from transformers import RobertaTokenizer, RobertaForSequenceClassification
from PIL import Image
from torchvision import transforms

"""Load TEXT model"""

TEXT_MODEL_DIR = "/content/drive/MyDrive/TASK01/models/final_task1a_text_roberta"

tokenizer = RobertaTokenizer.from_pretrained(TEXT_MODEL_DIR)
text_model = RobertaForSequenceClassification.from_pretrained(TEXT_MODEL_DIR)
text_model.eval()

"""Load IMAGE model"""

IMAGE_MODEL_DIR = "/content/drive/MyDrive/TASK01/models/final_task1a_image_vit"
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")


class ViTBinaryClassifier(nn.Module):
    def __init__(self):
        super().__init__()
        self.backbone = timm.create_model("vit_base_patch16_224", pretrained=False, num_classes=0)
        self.classifier = nn.Linear(768, 2)

    def forward(self, x):
        h = self.backbone.forward_features(x)
        cls_token = h[:, 0]
        return self.classifier(cls_token)


image_model = ViTBinaryClassifier().to(device)
image_model.load_state_dict(torch.load(f"{IMAGE_MODEL_DIR}/pytorch_model.bin", map_location=device))
image_model.eval()

"""Image preprocessing (same as training)"""

image_transform = transforms.Compose([
    transforms.Resize(256),
    transforms.CenterCrop(224),
    transforms.ToTensor(),
    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])
])

"""Text probability"""

def get_text_probs(text):
    inputs = tokenizer(
        text,
        return_tensors="pt",
        truncation=True,
        padding="max_length",
        max_length=128
    )

    with torch.no_grad():
        outputs = text_model(**inputs)

    probs = torch.softmax(outputs.logits, dim=1).cpu().numpy()[0]
    return probs

"""Image probability"""

def softmax_with_temp(logits, T=2.0):
    return F.softmax(logits / T, dim=1)

def get_image_probs(image_path):
    image = Image.open(image_path).convert("RGB")
    image = image_transform(image).unsqueeze(0).to(device)

    with torch.no_grad():
        logits = image_model(image)
        #print("Logits:", logits.cpu().numpy())
        probs = softmax_with_temp(logits, T=2.0).cpu().numpy()[0]

    return probs

"""Late Fusion function"""

def late_fusion(text, image_path, w_text=0.6, w_image=0.4):
    text_probs  = get_text_probs(text)
    image_probs = get_image_probs(image_path)

    final_probs = w_text * text_probs + w_image * image_probs
    pred_id = final_probs.argmax()

    return pred_id, final_probs, text_probs, image_probs

"""Test fusion on ONE sample"""

DATA_DIR = "/content/drive/MyDrive/TASK01/data/"

sample_text = "please help there are enemies"
sample_image = DATA_DIR + "sample_ss.jpg"

pred_id, final_probs, text_probs, image_probs = late_fusion(sample_text, sample_image)

labels = ["Not Informative", "Informative"]

print("TEXT probs :", text_probs)
print("IMAGE probs:", image_probs)
print("FINAL probs:", final_probs)
print("FINAL prediction:", labels[pred_id])

"""Evaluate Late Fusion on TEST dataset"""

import pandas as pd
from sklearn.metrics import accuracy_score, precision_recall_fscore_support

TEST_CSV = "/content/drive/MyDrive/TASK01/data/test_with_clean_text.csv"
test_df = pd.read_csv(TEST_CSV)

y_true = []
y_pred = []

for _, row in test_df.iterrows():

    text = row["clean_text"]
    img_path = "/content/drive/MyDrive/TASK01/data/" + row["image"]

    pred_id, _, _, _ = late_fusion(text, img_path)

    y_true.append(row["label_text_id"])   # same binary label
    y_pred.append(pred_id)


acc = accuracy_score(y_true, y_pred)
p, r, f1, _ = precision_recall_fscore_support(y_true, y_pred, average="binary")

print("Late Fusion Results")
print("Accuracy :", acc)
print("Precision:", p)
print("Recall   :", r)
print("F1-score :", f1)

