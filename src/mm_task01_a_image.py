# -*- coding: utf-8 -*-
"""MM_Task01_a_image.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1KBV1GNy5BSTK561jjXKldFAZSyusbjBU
"""

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd
import os

DATA_DIR = "/content/drive/MyDrive/TASK01/data/"

#train_df = pd.read_csv(DATA_DIR + "train_image.csv")
#dev_df   = pd.read_csv(DATA_DIR + "dev_image.csv")
#test_df  = pd.read_csv(DATA_DIR + "test_image.csv")

#train_df = pd.read_csv(DATA_DIR + "train_with_clean_text_RAW.csv")
#dev_df   = pd.read_csv(DATA_DIR + "dev_with_clean_text_RAW.csv")
#test_df  = pd.read_csv(DATA_DIR + "test_with_clean_text_RAW.csv")

train_df = pd.read_csv(DATA_DIR + "train_with_clean_text_RAW_dupes_gaps.csv")
dev_df   = pd.read_csv(DATA_DIR + "dev_with_clean_text_RAW_dupes_gaps.csv")
test_df  = pd.read_csv(DATA_DIR + "test_with_clean_text_RAW_dupes_gaps.csv")

#train_df = pd.read_csv(DATA_DIR + "train_balanced_text.csv")
#dev_df   = pd.read_csv(DATA_DIR + "dev_balanced_text.csv")
#test_df  = pd.read_csv(DATA_DIR + "test_balanced_text.csv")

print("Train size:", len(train_df))
print("Dev size:", len(dev_df))
print("Test size:", len(test_df))

print(train_df.columns)

"""Check label distribution"""

import numpy as np

def print_label_stats(df, split_name):
    counts = df["label_image"].value_counts().sort_index()
    total = len(df)
    print(f"\n{split_name} label distribution:")
    for label, count in counts.items():
        print(f"  Label {label}: {count} ({count/total:.2%})")

print_label_stats(train_df, "TRAIN")
print_label_stats(dev_df, "DEV")
print_label_stats(test_df, "TEST")

"""Compute class weights"""

import torch

counts = train_df["label_image"].value_counts().sort_index().values
class_weights = 1.0 / torch.tensor(counts, dtype=torch.float)
class_weights = class_weights / class_weights.sum()

print("Class weights:", class_weights)

"""**+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++**"""

print(train_df["image"].iloc[0])

from PIL import Image
import matplotlib.pyplot as plt

IMAGE_ROOT = "/content/drive/MyDrive/TASK01/data/"

img_path = IMAGE_ROOT + train_df.loc[0, "image"]
label = train_df.loc[0, "label_image"]

print("Image path:", img_path)
print("Label:", label)

img = Image.open(img_path).convert("RGB")
plt.imshow(img)
plt.axis("off")

"""Image preprocessing"""

from torchvision import transforms

image_transform = transforms.Compose([
    transforms.Resize(256),
    transforms.CenterCrop(224),
    transforms.ToTensor(),
    transforms.Normalize(
        mean=[0.485, 0.456, 0.406],
        std=[0.229, 0.224, 0.225]
    )
])

"""visualize original vs preprocessed image"""

import matplotlib.pyplot as plt
import torch
import numpy as np

def show_preprocessed_image(img_path, transform):
    img = Image.open(img_path).convert("RGB")
    img_tensor = transform(img)

    # Unnormalize for visualization
    mean = torch.tensor([0.485, 0.456, 0.406]).view(3,1,1)
    std  = torch.tensor([0.229, 0.224, 0.225]).view(3,1,1)

    img_unnorm = img_tensor * std + mean
    img_unnorm = img_unnorm.permute(1, 2, 0).numpy()
    img_unnorm = np.clip(img_unnorm, 0, 1)

    plt.figure(figsize=(8,4))

    plt.subplot(1,2,1)
    plt.title("Original Image")
    plt.imshow(img)
    plt.axis("off")

    plt.subplot(1,2,2)
    plt.title("After Preprocessing")
    plt.imshow(img_unnorm)
    plt.axis("off")

    plt.show()

img_path = IMAGE_ROOT + train_df.loc[0, "image"]
show_preprocessed_image(img_path, image_transform)

img_tensor = image_transform(img)
print(img_tensor.shape)

"""Dataset & DataLoaders (batch size = 10)"""

import os
from PIL import Image
from torch.utils.data import Dataset

# =========================
# Label mapping for Task-1(a)
# =========================
LABEL_MAP = {
    "not_informative": 0,
    "informative": 1
}


print("Label map sanity check:")
for k, v in LABEL_MAP.items():
    print(k, "→", v)

def add_label_id_column(df):
    df = df.copy()
    df["label_image_id"] = df["label_image"].map(LABEL_MAP)
    return df

train_df = add_label_id_column(train_df)
dev_df   = add_label_id_column(dev_df)
test_df  = add_label_id_column(test_df)

"""# **RUN TO SAVE LABELED CSV**"""

#RUN TO SAVE LABELED CSV

train_df.to_csv("train_with_label_id.csv", index=False)
dev_df.to_csv("dev_with_label_id.csv", index=False)
test_df.to_csv("test_with_label_id.csv", index=False)

print("Train labels:")
print(train_df[["label_image", "label_image_id"]].tail())

print("\nLabel distribution (train):")
print(train_df["label_image_id"].value_counts())

print(train_df["label_image_id"].value_counts())

class ImageDataset(Dataset):
    def __init__(self, df, image_root, transform=None):
        self.df = df.reset_index(drop=True)
        self.image_root = image_root
        self.transform = transform

    def __len__(self):
        return len(self.df)

    def __getitem__(self, idx):
        img_path = os.path.join(
            self.image_root,
            self.df.loc[idx, "image"]
        )

        label = int(self.df.loc[idx, "label_image_id"])

        image = Image.open(img_path).convert("RGB")

        if self.transform:
            image = self.transform(image)

        return image, label

train_ds = ImageDataset(
    train_df,
    IMAGE_ROOT,
    transform=image_transform
)

dev_ds = ImageDataset(
    dev_df,
    IMAGE_ROOT,
    transform=image_transform
)

test_ds = ImageDataset(
    test_df,
    IMAGE_ROOT,
    transform=image_transform
)

from torch.utils.data import DataLoader

train_loader = DataLoader(train_ds, batch_size=10, shuffle=True)
dev_loader   = DataLoader(dev_ds,   batch_size=10, shuffle=False)
test_loader  = DataLoader(test_ds,  batch_size=10, shuffle=False)

imgs, labels = next(iter(train_loader))

print(type(labels))
print(labels)
print(labels.dtype)

"""Vision Transformer (BEST – paper’s main result)"""

import timm
import torch.nn as nn

class ViTBinaryClassifier(nn.Module):
    def __init__(self):
        super().__init__()

        # ImageNet-pretrained ViT backbone
        self.backbone = timm.create_model(
            "vit_base_patch16_224",
            pretrained=True,
            num_classes=0   # remove classification head
        )

        # Binary classification head
        self.classifier = nn.Linear(768, 2)

    def forward(self, x):
        # Extract ViT features
        h = self.backbone.forward_features(x)  # [B, 197, 768]

        # CLS token representation
        cls_token = h[:, 0]                    # [B, 768]

        # Classification
        return self.classifier(cls_token)

class EarlyStopping:
    def __init__(self, patience=3):
        self.patience = patience
        self.best_loss = float("inf")
        self.counter = 0
        self.best_state = None

    def step(self, val_loss, model):
        if val_loss < self.best_loss:
            self.best_loss = val_loss
            self.counter = 0
            self.best_state = model.state_dict()
            return False
        else:
            self.counter += 1
            return self.counter >= self.patience

"""Training and Validation Procedure"""

import torch
import torch.nn as nn

def train_model(model, train_loader, dev_loader, device):
    model.to(device)

    criterion = nn.CrossEntropyLoss(weight=class_weights.to(device))
    optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)

    early_stopper = EarlyStopping(patience=3)

    for epoch in range(10):
        # ===== Training =====
        model.train()
        train_loss = 0.0

        for imgs, labels in train_loader:
            imgs, labels = imgs.to(device), labels.to(device)

            optimizer.zero_grad()
            logits = model(imgs)
            loss = criterion(logits, labels)
            loss.backward()
            optimizer.step()

            train_loss += loss.item()

        train_loss /= len(train_loader)

        # ===== Validation =====
        model.eval()
        val_loss = 0.0

        with torch.no_grad():
            for imgs, labels in dev_loader:
                imgs, labels = imgs.to(device), labels.to(device)
                logits = model(imgs)
                loss = criterion(logits, labels)
                val_loss += loss.item()

        val_loss /= len(dev_loader)

        print(f"Epoch {epoch+1}: Train Loss={train_loss:.4f}, Val Loss={val_loss:.4f}")

        if early_stopper.step(val_loss, model):
            print("Early stopping triggered")
            break

    # Restore best model
    model.load_state_dict(early_stopper.best_state)
    return model

"""Model Evaluation"""

from sklearn.metrics import accuracy_score, precision_recall_fscore_support

def evaluate(model, loader, device):
    model.eval()
    y_true, y_pred = [], []

    with torch.no_grad():
        for imgs, labels in loader:
            imgs = imgs.to(device)
            logits = model(imgs)
            preds = torch.argmax(logits, dim=1).cpu().numpy()

            y_true.extend(labels.numpy())
            y_pred.extend(preds)

    acc = accuracy_score(y_true, y_pred)
    p, r, f1, _ = precision_recall_fscore_support(
        y_true, y_pred, average="weighted"
    )

    return acc, p, r, f1

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

model = ViTBinaryClassifier()
#model, history = train_model(model, train_loader, dev_loader, device)#added to get curves(optional)

print("===== Training Vision Transformer =====")
model = train_model(model, train_loader, dev_loader, device)

acc, p, r, f1 = evaluate(model, test_loader, device)

print("Vision Transformer Test Results:")
print(f"  Accuracy : {acc:.4f}")
print(f"  Precision: {p:.4f}")
print(f"  Recall   : {r:.4f}")
print(f"  F1-score : {f1:.4f}")

"""TEST

Plot LOSS curves (Train vs Validation) NOT WORKING
"""

import matplotlib.pyplot as plt

epochs = range(1, len(history["train_loss"]) + 1)

plt.figure(figsize=(8, 5))
plt.plot(epochs, history["train_loss"], marker="o", label="Training Loss")
plt.plot(epochs, history["val_loss"], marker="o", label="Validation Loss")
plt.xlabel("Epoch")
plt.ylabel("Loss")
plt.title("Training vs Validation Loss (Image Model)")
plt.legend()
plt.grid(True)
plt.show()

"""Plot ACCURACY curves (Train vs Validation) NOT WORKING"""

plt.figure(figsize=(8, 5))
plt.plot(epochs, history["train_acc"], marker="o", label="Training Accuracy")
plt.plot(epochs, history["val_acc"], marker="o", label="Validation Accuracy")
plt.xlabel("Epoch")
plt.ylabel("Accuracy")
plt.title("Training vs Validation Accuracy (Image Model)")
plt.legend()
plt.grid(True)
plt.show()

"""Confusion Matrix"""

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
import matplotlib.pyplot as plt
import numpy as np

# Get predictions on TEST set
y_true, y_pred = get_predictions(model, test_loader, device)

# Confusion matrix
cm = confusion_matrix(y_true, y_pred)

disp = ConfusionMatrixDisplay(
    confusion_matrix=cm,
    display_labels=["Not Informative", "Informative"]
)

plt.figure(figsize=(5, 5))
disp.plot(cmap="Greens", values_format="d")
plt.title("Confusion Matrix (Image Model – Test Set)")
plt.grid(False)
plt.show()

"""Use it anywhere:"""

plot_confusion_matrix(model, train_loader, device, "Confusion Matrix – TRAIN")
plot_confusion_matrix(model, dev_loader, device, "Confusion Matrix – DEV")
plot_confusion_matrix(model, test_loader, device, "Confusion Matrix – TEST")

"""test with own image"""

id2label = {
    0: "Not Informative",
    1: "Informative"
}

from PIL import Image

def predict_image(image_path, model, transform, device):
    model.eval()

    image = Image.open(image_path).convert("RGB")
    image = transform(image).unsqueeze(0).to(device)

    with torch.no_grad():
        logits = model(image)
        probs = torch.softmax(logits, dim=1).cpu().numpy()[0]
        pred_id = probs.argmax()

    return pred_id, probs

img_path = "sample_disaster_image.jpg"

pred_id, probs = predict_image(
    img_path,
    model,
    image_transform,
    device
)

print("Prediction:", id2label[pred_id])
print("Probabilities:")
print(f"Not Informative: {probs[0]:.4f}")
print(f"Informative    : {probs[1]:.4f}")

"""SAVE IMAGE MODEL (ViT – Task-01A)"""

# ===== SAVE TASK-01A IMAGE MODEL =====

MODEL_DIR = "/content/drive/MyDrive/TASK01/models/final_task1a_image_vit"
import os
import torch
import json

os.makedirs(MODEL_DIR, exist_ok=True)

# Save model weights
torch.save(model.state_dict(), os.path.join(MODEL_DIR, "pytorch_model.bin"))

# Save label map
label_map = {
    "id2label": {
        0: "Not Informative",
        1: "Informative"
    },
    "label2id": {
        "Not Informative": 0,
        "Informative": 1
    }
}

with open(os.path.join(MODEL_DIR, "label_map.json"), "w") as f:
    json.dump(label_map, f, indent=4)

# Save model config (important for reproducibility)
model_config = {
    "backbone": "vit_base_patch16_224",
    "num_classes": 2,
    "image_size": 224,
    "task": "Task-01A Image Binary Classification"
}

with open(os.path.join(MODEL_DIR, "model_config.json"), "w") as f:
    json.dump(model_config, f, indent=4)

print("✅ Image model saved to:", MODEL_DIR)

"""LOAD IMAGE MODEL (Later / New Session)"""

# ===== LOAD TASK-01A IMAGE MODEL =====

import torch
import json
import timm
import torch.nn as nn

MODEL_DIR = "/content/drive/MyDrive/TASK01/models/final_task1a_image_vit"
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# Recreate model architecture (MUST match training)
class ViTBinaryClassifier(nn.Module):
    def __init__(self):
        super().__init__()
        self.backbone = timm.create_model(
            "vit_base_patch16_224",
            pretrained=False,   # IMPORTANT: False when loading weights
            num_classes=0
        )
        self.classifier = nn.Linear(768, 2)

    def forward(self, x):
        h = self.backbone.forward_features(x)
        cls_token = h[:, 0]
        return self.classifier(cls_token)

# Initialize model
model = ViTBinaryClassifier().to(device)

# Load weights
model.load_state_dict(
    torch.load(os.path.join(MODEL_DIR, "pytorch_model.bin"), map_location=device)
)

model.eval()

# Load label map
with open(os.path.join(MODEL_DIR, "label_map.json"), "r") as f:
    label_map = json.load(f)

id2label = {int(k): v for k, v in label_map["id2label"].items()}

print("✅ Image model and label map loaded successfully!")

"""TEST LOADED IMAGE MODEL (Sanity Check)"""

from PIL import Image
import torch.nn.functional as F

def predict_image(image_path, model, transform, device):
    model.eval()

    image = Image.open(image_path).convert("RGB")
    image = transform(image).unsqueeze(0).to(device)

    with torch.no_grad():
        logits = model(image)
        probs = F.softmax(logits, dim=1).cpu().numpy()[0]
        pred_id = probs.argmax()

    return pred_id, probs


img_path = "sample_disaster_image.jpg"  # your test image

pred_id, probs = predict_image(
    img_path,
    model,
    image_transform,
    device
)

print("Prediction:", id2label[pred_id])
print(f"Not Informative: {probs[0]:.4f}")
print(f"Informative    : {probs[1]:.4f}")





"""# **END**"""



