# -*- coding: utf-8 -*-
"""MM_Task01_b_image.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1niGzezpgfxlU4XNa77nm7qEuCb1dEzFp
"""

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd
import os

DATA_DIR = "/content/drive/MyDrive/TASK01/data/"

train_df = pd.read_csv(DATA_DIR + "train_event_gap_reduced.csv")
dev_df   = pd.read_csv(DATA_DIR + "dev_event_gap_reduced.csv")
test_df  = pd.read_csv(DATA_DIR + "test_event_gap_reduced.csv")

print("Train size:", len(train_df))
print("Dev size:", len(dev_df))
print("Test size:", len(test_df))
print(train_df.columns)

"""multiclass mapping"""

# =========================
# Event name → class ID
# =========================
LABEL_MAP = {
    "earthquake": 0,
    "floods": 1,
    "hurricane": 2,
    "wildfires": 3
}

print("Label map:")
for k, v in LABEL_MAP.items():
    print(f"{v} -> {k}")

def add_label_id_column(df):
    df = df.copy()
    df["label_image_id"] = df["event_name"].map(LABEL_MAP)
    return df

train_df = add_label_id_column(train_df)
dev_df   = add_label_id_column(dev_df)
test_df  = add_label_id_column(test_df)

print(train_df[["event_name", "label_image_id"]].tail())

train_df.head(3)

import torch

def print_label_stats(df, split_name):
    counts = df["label_image_id"].value_counts().sort_index()
    total = len(df)
    print(f"\n{split_name} label distribution:")
    for label, count in counts.items():
        print(f"  Class {label}: {count} ({count/total:.2%})")

print_label_stats(train_df, "TRAIN")
print_label_stats(dev_df, "DEV")
print_label_stats(test_df, "TEST")

"""Compute class weights"""

counts = train_df["label_image_id"].value_counts().sort_index().values
class_weights = 1.0 / torch.tensor(counts, dtype=torch.float)
class_weights = class_weights / class_weights.sum()

print("Class weights:", class_weights)

"""Preproccessing"""

from PIL import Image
import matplotlib.pyplot as plt

IMAGE_ROOT = "/content/drive/MyDrive/TASK01/data/"

img_path = IMAGE_ROOT + train_df.loc[0, "image"]
label = train_df.loc[0, "label_image_id"]

print("Image path:", img_path)
print("Label:", label)

img = Image.open(img_path).convert("RGB")
plt.imshow(img)
plt.axis("off")

from torchvision import transforms

image_transform = transforms.Compose([
    transforms.Resize(256),
    transforms.CenterCrop(224),
    transforms.ToTensor(),
    transforms.Normalize(
        mean=[0.485, 0.456, 0.406],
        std=[0.229, 0.224, 0.225]
    )
])

from torchvision import transforms
from PIL import Image
import torch

img_path = IMAGE_ROOT + train_df.loc[0, "image"]

tensor_only = transforms.ToTensor()
img = Image.open(img_path).convert("RGB")
img_tensor = tensor_only(img)

print("Min pixel value:", img_tensor.min().item())
print("Max pixel value:", img_tensor.max().item())

import matplotlib.pyplot as plt
import torch
import numpy as np

def show_preprocessed_image(img_path, transform):
    img = Image.open(img_path).convert("RGB")
    img_tensor = transform(img)

    # Unnormalize for visualization
    mean = torch.tensor([0.485, 0.456, 0.406]).view(3,1,1)
    std  = torch.tensor([0.229, 0.224, 0.225]).view(3,1,1)

    img_unnorm = img_tensor * std + mean
    img_unnorm = img_unnorm.permute(1, 2, 0).numpy()
    img_unnorm = np.clip(img_unnorm, 0, 1)

    plt.figure(figsize=(8,4))

    plt.subplot(1,2,1)
    plt.title("Original Image")
    plt.imshow(img)
    plt.axis("off")

    plt.subplot(1,2,2)
    plt.title("After Preprocessing")
    plt.imshow(img_unnorm)
    plt.axis("off")

    plt.show()

img_path = IMAGE_ROOT + train_df.loc[0, "image"]
show_preprocessed_image(img_path, image_transform)

img_tensor = image_transform(img)
print(img_tensor.shape)

"""Dataset & DataLoaders"""

from torch.utils.data import Dataset, DataLoader
from PIL import Image

IMAGE_ROOT = DATA_DIR

class ImageDataset(Dataset):
    def __init__(self, df, image_root, transform=None):
        self.df = df.reset_index(drop=True)
        self.image_root = image_root
        self.transform = transform

    def __len__(self):
        return len(self.df)

    def __getitem__(self, idx):
        img_path = os.path.join(self.image_root, self.df.loc[idx, "image"])
        label = int(self.df.loc[idx, "label_image_id"])

        image = Image.open(img_path).convert("RGB")
        if self.transform:
            image = self.transform(image)

        return image, label

train_ds = ImageDataset(train_df, IMAGE_ROOT, image_transform)
dev_ds   = ImageDataset(dev_df, IMAGE_ROOT, image_transform)
test_ds  = ImageDataset(test_df, IMAGE_ROOT, image_transform)

train_loader = DataLoader(train_ds, batch_size=10, shuffle=True)
dev_loader   = DataLoader(dev_ds, batch_size=10, shuffle=False)
test_loader  = DataLoader(test_ds, batch_size=10, shuffle=False)

imgs, labels = next(iter(train_loader))

print(type(labels))
print(labels)
print(labels.dtype)

"""MODEL: Binary → 4-class ViT"""

import timm
import torch.nn as nn

class ViTMulticlassClassifier(nn.Module):
    def __init__(self, num_classes=4):
        super().__init__()

        self.backbone = timm.create_model(
            "vit_base_patch16_224",
            pretrained=True,
            num_classes=0
        )

        self.classifier = nn.Linear(768, num_classes)

    def forward(self, x):
        h = self.backbone.forward_features(x)  # [B, 197, 768]
        cls_token = h[:, 0]
        return self.classifier(cls_token)

class EarlyStopping:
    def __init__(self, patience=3):
        self.patience = patience
        self.best_loss = float("inf")
        self.counter = 0
        self.best_state = None

    def step(self, val_loss, model):
        if val_loss < self.best_loss:
            self.best_loss = val_loss
            self.counter = 0
            self.best_state = model.state_dict()
            return False
        else:
            self.counter += 1
            return self.counter >= self.patience

"""Training (only loss stays CrossEntropy)"""

import torch
import torch.nn as nn

def train_model(model, train_loader, dev_loader, device):
    model.to(device)

    criterion = nn.CrossEntropyLoss(weight=class_weights.to(device))
    optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)

    early_stopper = EarlyStopping(patience=3)

    for epoch in range(10):
        model.train()
        train_loss = 0.0

        for imgs, labels in train_loader:
            imgs, labels = imgs.to(device), labels.to(device)

            optimizer.zero_grad()
            logits = model(imgs)
            loss = criterion(logits, labels)
            loss.backward()
            optimizer.step()

            train_loss += loss.item()

        train_loss /= len(train_loader)

        model.eval()
        val_loss = 0.0
        with torch.no_grad():
            for imgs, labels in dev_loader:
                imgs, labels = imgs.to(device), labels.to(device)
                logits = model(imgs)
                loss = criterion(logits, labels)
                val_loss += loss.item()

        val_loss /= len(dev_loader)

        print(f"Epoch {epoch+1}: Train={train_loss:.4f}, Val={val_loss:.4f}")

        if early_stopper.step(val_loss, model):
            print("Early stopping triggered")
            break

    model.load_state_dict(early_stopper.best_state)
    return model

"""Evaluation (works for multiclass automatically)"""

from sklearn.metrics import accuracy_score, precision_recall_fscore_support

def evaluate(model, loader, device):
    model.eval()
    y_true, y_pred = [], []

    with torch.no_grad():
        for imgs, labels in loader:
            imgs = imgs.to(device)
            logits = model(imgs)
            preds = torch.argmax(logits, dim=1).cpu().numpy()

            y_true.extend(labels.numpy())
            y_pred.extend(preds)

    acc = accuracy_score(y_true, y_pred)
    p, r, f1, _ = precision_recall_fscore_support(
        y_true, y_pred, average="weighted"
    )

    return acc, p, r, f1

"""Train, evaluate"""

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

model = ViTMulticlassClassifier(num_classes=4)

print("===== Training ViT (4-class event classification) =====")
model = train_model(model, train_loader, dev_loader, device)

acc, p, r, f1 = evaluate(model, test_loader, device)

print("Test Results:")
print(f"Accuracy : {acc:.4f}")
print(f"Precision: {p:.4f}")
print(f"Recall   : {r:.4f}")
print(f"F1-score : {f1:.4f}")

"""CONFUSION MATRIX"""

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
import matplotlib.pyplot as plt
import numpy as np

# Collect predictions
y_true, y_pred = [], []

model.eval()
with torch.no_grad():
    for imgs, labels in test_loader:
        imgs = imgs.to(device)
        logits = model(imgs)
        preds = torch.argmax(logits, dim=1).cpu().numpy()

        y_true.extend(labels.numpy())
        y_pred.extend(preds)

y_true = np.array(y_true)
y_pred = np.array(y_pred)

# Confusion matrix
cm = confusion_matrix(y_true, y_pred)

disp = ConfusionMatrixDisplay(
    confusion_matrix=cm,
    display_labels=["Earthquake", "Floods", "Hurricane", "Wildfires"]
)

plt.figure(figsize=(6, 6))
disp.plot(cmap="Blues", values_format="d")
plt.title("Confusion Matrix – Task-01B Image (Test Set)")
plt.grid(False)
plt.show()

"""CLASSIFICATION REPORT"""

from sklearn.metrics import classification_report

print(
    classification_report(
        y_true,
        y_pred,
        target_names=["Earthquake", "Floods", "Hurricane", "Wildfires"],
        digits=4
    )
)

"""save the model"""

# ===== SAVE TASK-01B IMAGE MODEL (MULTICLASS) =====

MODEL_DIR = "/content/drive/MyDrive/TASK01/models/final_task1b_image_vit"
import os
import torch
import json

os.makedirs(MODEL_DIR, exist_ok=True)

# Save model weights
torch.save(
    model.state_dict(),
    os.path.join(MODEL_DIR, "pytorch_model.bin")
)

# Save label map (event classification)
label_map = {
    "id2label": {
        0: "earthquake",
        1: "floods",
        2: "hurricane",
        3: "wildfires"
    },
    "label2id": {
        "earthquake": 0,
        "floods": 1,
        "hurricane": 2,
        "wildfires": 3
    }
}

with open(os.path.join(MODEL_DIR, "label_map.json"), "w") as f:
    json.dump(label_map, f, indent=4)

# Save model configuration (for reproducibility)
model_config = {
    "task": "Task-01B Image Event Classification",
    "architecture": "ViT",
    "backbone": "vit_base_patch16_224",
    "num_classes": 4,
    "image_size": 224
}

with open(os.path.join(MODEL_DIR, "model_config.json"), "w") as f:
    json.dump(model_config, f, indent=4)

print("✅ Task-01B Image model saved to:", MODEL_DIR)

"""LOAD MODEL (Task-01B Image – ViT Multiclass)"""

# ===== LOAD TASK-01B IMAGE MODEL (MULTICLASS) =====

import torch
import json
import timm
import torch.nn as nn

MODEL_DIR = "/content/drive/MyDrive/TASK01/models/final_task1b_image_vit"
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# Recreate the EXACT model architecture
class ViTMulticlassClassifier(nn.Module):
    def __init__(self, num_classes=4):
        super().__init__()
        self.backbone = timm.create_model(
            "vit_base_patch16_224",
            pretrained=False,   # IMPORTANT when loading weights
            num_classes=0
        )
        self.classifier = nn.Linear(768, num_classes)

    def forward(self, x):
        h = self.backbone.forward_features(x)
        cls_token = h[:, 0]
        return self.classifier(cls_token)

# Initialize model
model = ViTMulticlassClassifier(num_classes=4).to(device)

# Load trained weights
model.load_state_dict(
    torch.load(
        os.path.join(MODEL_DIR, "pytorch_model.bin"),
        map_location=device
    )
)

model.eval()

# Load label map
with open(os.path.join(MODEL_DIR, "label_map.json"), "r") as f:
    label_map = json.load(f)

id2label = {int(k): v for k, v in label_map["id2label"].items()}

print("✅ Task-01B Image model loaded successfully!")

"""TEST LOADED MODEL (Sanity Check)"""

from PIL import Image
import torch.nn.functional as F

def predict_image(image_path, model, transform, device):
    model.eval()

    image = Image.open(image_path).convert("RGB")
    image = transform(image).unsqueeze(0).to(device)

    with torch.no_grad():
        logits = model(image)
        probs = F.softmax(logits, dim=1).cpu().numpy()[0]
        pred_id = probs.argmax()

    return pred_id, probs


img_path = DATA_DIR + "sample_image_1.jpg"  # replace with your image

pred_id, probs = predict_image(
    img_path,
    model,
    image_transform,
    device
)

print("Prediction:", id2label[pred_id])
print("Probabilities:")
for i, p in enumerate(probs):
    print(f"{id2label[i]}: {p:.4f}")





