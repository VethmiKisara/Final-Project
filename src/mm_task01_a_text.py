# -*- coding: utf-8 -*-
"""MM_Task01_a_text.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1bwuIcRifUA2ssiIyBnaxVawLU4KCtrBi
"""

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd
import os

DATA_DIR = "/content/drive/MyDrive/TASK01/data/"

#train_df = pd.read_csv(DATA_DIR + "train_balanced_text.csv")
#dev_df   = pd.read_csv(DATA_DIR + "dev_balanced_text.csv")
#test_df  = pd.read_csv(DATA_DIR + "test_balanced_text.csv")

train_df = pd.read_csv(DATA_DIR + "train_with_clean_text_RAW_dupes_gaps.csv")
dev_df   = pd.read_csv(DATA_DIR + "dev_with_clean_text_RAW_dupes_gaps.csv")
test_df  = pd.read_csv(DATA_DIR + "test_with_clean_text_RAW_dupes_gaps.csv")

print("Train size:", len(train_df))
print("Dev size:", len(dev_df))
print("Test size:", len(test_df))

print(train_df.columns)

train_df.head(3)

train_df["label_text"].value_counts()

dev_df["label_text"].value_counts()

test_df["label_text"].value_counts()

!pip install emoji

import matplotlib.pyplot as plt
import seaborn as sns
import re
import nltk
import emoji
from nltk.corpus import stopwords
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout
from tensorflow.keras.utils import to_categorical

nltk.download('stopwords')
stop_words = set(stopwords.words('english'))

print(train_df["label_text"].unique())
print(dev_df["label_text"].unique())
print(test_df["label_text"].unique())

label_map = {
    "non-informative": 0,
    "informative": 1
}

train_df["label_text_id"] = train_df["label_text"].map(label_map)
dev_df["label_text_id"]   = dev_df["label_text"].map(label_map)
test_df["label_text_id"]  = test_df["label_text"].map(label_map)

train_df[["label_text", "label_text_id"]].head(5)

print(train_df["label_text_id"].value_counts())
print(dev_df["label_text_id"].value_counts())
print(test_df["label_text_id"].value_counts())

train_df["label_text"].value_counts()

label_map = {
    "not_informative": 0,
    "informative": 1
}

train_df["label_text_id"] = train_df["label_text"].map(label_map)
dev_df["label_text_id"]   = dev_df["label_text"].map(label_map)
test_df["label_text_id"]  = test_df["label_text"].map(label_map)

print(train_df["label_text_id"].value_counts())
print(dev_df["label_text_id"].value_counts())
print(test_df["label_text_id"].value_counts())

print(train_df["label_text_id"].isnull().sum())
print(dev_df["label_text_id"].isnull().sum())
print(test_df["label_text_id"].isnull().sum())

pip install nltk emoji pyspellchecker contractions

import nltk
nltk.download("stopwords")
nltk.download("punkt")
nltk.download('punkt_tab')

import re
import string
import emoji
import contractions
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
from spellchecker import SpellChecker

stop_words = set(stopwords.words("english"))
spell = SpellChecker()

def preprocess_text(text):
    # 1. Convert to string and lowercase
    text = str(text).lower()

    # 2. Remove URLs
    text = re.sub(r"http\S+|www\S+", "", text)

    # 3. Remove hashtag symbol (keep the word)
    text = re.sub(r"#", "", text)

    # 4. Convert emojis/emoticons to text
    text = emoji.demojize(text)

    # 5. Expand contractions (abbreviations)
    # e.g. can't â†’ cannot, isn't â†’ is not
    text = contractions.fix(text)

    # 6. Remove non-ASCII characters
    text = re.sub(r"[^\x00-\x7F]+", "", text)

    # 7. Replace punctuation with whitespace
    text = re.sub(f"[{re.escape(string.punctuation)}]", " ", text)

    # 8. Tokenize
    tokens = word_tokenize(text)

    # 9. Remove stopwords
    tokens = [t for t in tokens if t not in stop_words]

    # 10. Correct misspelled words (light correction)
    #tokens = [spell.correction(t) if spell.correction(t) else t for t in tokens]

    # 11. Rejoin tokens
    text = " ".join(tokens)

    # 12. Normalize whitespace
    text = re.sub(r"\s+", " ", text).strip()

    return text

"""Done To Here..**CONTINUE FROM HERE**"""

dev_df["clean_text"]   = dev_df["tweet_text"].apply(preprocess_text)

dev_df.to_csv(DATA_DIR + "dev_with_clean_text.csv", index=False)

test_df["clean_text"]  = test_df["tweet_text"].apply(preprocess_text)

test_df.to_csv(DATA_DIR + "test_with_clean_text.csv", index=False)

train_df["clean_text"] = train_df["tweet_text"].apply(preprocess_text)

train_df.to_csv(DATA_DIR + "train_with_clean_text.csv", index=False)



print("Train:", train_df.shape)
print("Dev:", dev_df.shape)
print("Test:", test_df.shape)

print(train_df.columns)

train_df[["tweet_text", "clean_text"]].sample(5, random_state=42)

empty_count = (train_df["clean_text"].str.strip() == "").sum()
total = len(train_df)

print(f"Empty clean_text rows: {empty_count} / {total}")
print(f"Percentage: {empty_count / total * 100:.2f}%")

train_df["clean_text"].str.len().describe()

"""**preproccessing completed**"""

train_df.columns
# ['tweet_id', 'clean_text', 'label_text_id', ...]

!pip install -q transformers datasets accelerate evaluate

import torch
import pandas as pd
import numpy as np

from transformers import (
    RobertaTokenizer,
    RobertaForSequenceClassification,
    Trainer,
    TrainingArguments
)

from sklearn.metrics import accuracy_score, precision_recall_fscore_support

"""Load Preprocessed Files"""

DATA_DIR = "/content/drive/MyDrive/TASK01/data/"

train_df = pd.read_csv(DATA_DIR + "train_with_clean_text.csv")
dev_df   = pd.read_csv(DATA_DIR + "dev_with_clean_text.csv")
test_df  = pd.read_csv(DATA_DIR + "test_with_clean_text.csv")

print(len(train_df), len(dev_df), len(test_df))

assert set(train_df["label_text_id"].unique()) == {0, 1}
assert train_df["clean_text"].isnull().sum() == 0

MODEL_NAME = "roberta-large"
MAX_LEN = 128

tokenizer = RobertaTokenizer.from_pretrained(MODEL_NAME)

class TweetDataset(torch.utils.data.Dataset):
    def __init__(self, texts, labels, tokenizer):
        self.encodings = tokenizer(
            texts,
            truncation=True,
            padding="max_length",
            max_length=MAX_LEN
        )
        self.labels = labels

    def __getitem__(self, idx):
        item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}
        item["labels"] = torch.tensor(self.labels[idx], dtype=torch.long)
        return item

    def __len__(self):
        return len(self.labels)

train_dataset = TweetDataset(
    train_df["clean_text"].tolist(),
    train_df["label_text_id"].tolist(),
    tokenizer
)

dev_dataset = TweetDataset(
    dev_df["clean_text"].tolist(),
    dev_df["label_text_id"].tolist(),
    tokenizer
)

test_dataset = TweetDataset(
    test_df["clean_text"].tolist(),
    test_df["label_text_id"].tolist(),
    tokenizer
)

model = RobertaForSequenceClassification.from_pretrained(
    MODEL_NAME,
    num_labels=2
)

def compute_metrics(eval_pred):
    logits, labels = eval_pred
    preds = np.argmax(logits, axis=1)

    precision, recall, f1, _ = precision_recall_fscore_support(
        labels, preds, average="binary"
    )
    acc = accuracy_score(labels, preds)

    return {
        "accuracy": acc,
        "precision": precision,
        "recall": recall,
        "f1": f1,
    }

training_args = TrainingArguments(
    output_dir="./task1a_text_roberta",
    eval_strategy="epoch",
    save_strategy="epoch",
    learning_rate=1e-6,              # ðŸ”¥ paper value
    per_device_train_batch_size=16,  # ðŸ”¥ paper value
    per_device_eval_batch_size=16,
    num_train_epochs=10,             # ðŸ”¥ paper value
    weight_decay=0.01,
    logging_steps=100,
    load_best_model_at_end=True,
    metric_for_best_model="f1",
    greater_is_better=True,
    report_to="none"
)

trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=train_dataset,
    eval_dataset=dev_dataset,
    tokenizer=tokenizer,
    compute_metrics=compute_metrics
)

trainer.train()

test_results = trainer.evaluate(test_dataset)
print(test_results)

"""TEST"""

import matplotlib.pyplot as plt

train_losses = []
eval_losses = []

for log in trainer.state.log_history:
    if "loss" in log and "eval_loss" not in log:
        train_losses.append(log["loss"])
    if "eval_loss" in log:
        eval_losses.append(log["eval_loss"])

plt.figure(figsize=(8, 5))
plt.plot(train_losses, label="Training Loss")
plt.plot(eval_losses, label="Validation Loss")
plt.xlabel("Epoch")
plt.ylabel("Loss")
plt.title("Training vs Validation Loss")
plt.legend()
plt.grid(True)
plt.show()

"""Accuracy Curve"""

train_acc = []
eval_acc = []
epochs = []

for log in trainer.state.log_history:
    # Training accuracy (logged during training steps)
    if "accuracy" in log and "eval_accuracy" not in log:
        train_acc.append(log["accuracy"])

    # Validation accuracy (logged at eval_strategy="epoch")
    if "eval_accuracy" in log:
        eval_acc.append(log["eval_accuracy"])
        epochs.append(log["epoch"])

import matplotlib.pyplot as plt

plt.figure(figsize=(8, 5))

if len(train_acc) == len(eval_acc):
    plt.plot(epochs, train_acc, marker="o", label="Training Accuracy")

plt.plot(epochs, eval_acc, marker="o", label="Validation Accuracy")

plt.xlabel("Epoch")
plt.ylabel("Accuracy")
plt.title("Training vs Validation Accuracy")
plt.legend()
plt.grid(True)
plt.show()

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay

# Predict on dev set
dev_output = trainer.predict(dev_dataset)

y_true = dev_output.label_ids
y_pred = np.argmax(dev_output.predictions, axis=1)

cm = confusion_matrix(y_true, y_pred)

disp = ConfusionMatrixDisplay(
    confusion_matrix=cm,
    display_labels=["Not Informative", "Informative"]
)

disp.plot(cmap="Blues", values_format="d")
plt.title("Confusion Matrix (Validation Set)")
plt.show()

from sklearn.metrics import classification_report

print(
    classification_report(
        y_true,
        y_pred,
        target_names=["Not Informative", "Informative"],
        digits=4
    )
)

"""test with own text"""

id2label = {
    0: "Not Informative",
    1: "Informative"
}

def predict_text(text, tokenizer, model, max_len=128):
    model.eval()

    inputs = tokenizer(
        text,
        return_tensors="pt",
        truncation=True,
        padding="max_length",
        max_length=max_len
    )

    with torch.no_grad():
        outputs = model(**inputs)

    logits = outputs.logits
    probs = torch.softmax(logits, dim=1).cpu().numpy()[0]
    pred_id = probs.argmax()

    return pred_id, probs

sample_text = "there are still people in the buildings we need to recure them asap"

pred_id, probs = predict_text(sample_text, tokenizer, trainer.model)

print("Input text:")
print(sample_text)

print("\nPrediction:", id2label[pred_id])

print("\nClass probabilities:")
for i, p in enumerate(probs):
    print(f"{id2label[i]}: {p:.4f}")

"""SAVE MODEL (to Google Drive)"""

#trainer.save_model("./final_task1a_text_roberta")
#tokenizer.save_pretrained("./final_task1a_text_roberta")

# ===== SAVE TASK-01A TEXT MODEL =====

MODEL_DIR = "/content/drive/MyDrive/TASK01/models/final_task1a_text_roberta"

import os
os.makedirs(MODEL_DIR, exist_ok=True)

# Save HuggingFace Trainer model
trainer.save_model(MODEL_DIR)

# Save tokenizer
tokenizer.save_pretrained(MODEL_DIR)

# Save label mapping (since NO LabelEncoder is used)
import json

id2label = {
    0: "Not Informative",
    1: "Informative"
}

label2id = {
    "Not Informative": 0,
    "Informative": 1
}

with open(os.path.join(MODEL_DIR, "label_map.json"), "w") as f:
    json.dump(
        {"id2label": id2label, "label2id": label2id},
        f,
        indent=4
    )

print("âœ… Task-01A Text model saved to:", MODEL_DIR)

"""LOAD MODEL (Later / New Session)"""

# ===== LOAD TASK-01A TEXT MODEL =====

from transformers import RobertaForSequenceClassification, RobertaTokenizer
import json
import torch

MODEL_DIR = "/content/drive/MyDrive/TASK01/models/final_task1a_text_roberta"

# Load tokenizer
tokenizer = RobertaTokenizer.from_pretrained(MODEL_DIR)

# Load model
model = RobertaForSequenceClassification.from_pretrained(MODEL_DIR)

model.eval()

# Load label map
with open(f"{MODEL_DIR}/label_map.json", "r") as f:
    label_map = json.load(f)

id2label = {int(k): v for k, v in label_map["id2label"].items()}

print("âœ… Model, tokenizer, and label map loaded successfully!")

"""TEST LOADED MODEL (Sanity Check)"""

# ===== TEST LOADED MODEL =====

text = "today is my dog's birthday but it dead 4 years ago"

inputs = tokenizer(
    text,
    return_tensors="pt",
    truncation=True,
    padding="max_length",
    max_length=128
)

with torch.no_grad():
    outputs = model(**inputs)

pred_id = outputs.logits.argmax(dim=1).item()
pred_label = id2label[pred_id]

print("Input:", text)
print("Prediction:", pred_label)



"""**END**"""





